{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 19:17:00.911847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 19:17:00.911869: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import keras.losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "import pydicom.pixel_data_handlers\n",
    "import nibabel as nib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import CategoryEncoding, IntegerLookup\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "CURRENT_DIR_PATH = os.getcwd()\n",
    "\n",
    "TRAIN_IMAGE_PATH = os.path.join(CURRENT_DIR_PATH, \"train_images\")\n",
    "SEGMENTATIONS_PATH = os.path.join(CURRENT_DIR_PATH, \"segmentations\")\n",
    "TRAIN_CSV_PATH = os.path.join(CURRENT_DIR_PATH, \"train.csv\")\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 75"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "def pad_list(labels_to_pad):\n",
    "    return [labels_to_pad[len(labels_to_pad) - 1] if i >= len(labels_to_pad) else labels_to_pad[i] for i in range(0, 8)]\n",
    "\n",
    "def labels_for_image(vertebrae):\n",
    "    vertebrae_for_image = list(filter(lambda vertebra: vertebra > 0, vertebrae))\n",
    "    labels_to_pad = list((map(lambda vertebra: int(vertebra), vertebrae_for_image))) if len(vertebrae_for_image) > 0 else [0]\n",
    "    padded_labels = pad_list(labels_to_pad)\n",
    "    return padded_labels\n",
    "\n",
    "def preprocess_data():\n",
    "    segmentation_patient_files = os.listdir(SEGMENTATIONS_PATH)\n",
    "    train_images = []\n",
    "    train_image_labels = []\n",
    "\n",
    "    for segmentation_patient_file in segmentation_patient_files:\n",
    "        file_path = os.path.join(SEGMENTATIONS_PATH, segmentation_patient_file)\n",
    "        segmentation_file = nib.load(file_path).get_fdata()\n",
    "        segmentation_file_transposed = segmentation_file[:, ::-1, ::-1].transpose(2, 1, 0)\n",
    "\n",
    "        for slice_number in range(0, len(segmentation_file_transposed)):\n",
    "            dicom_slice = segmentation_file_transposed[slice_number]\n",
    "            vertebrae = np.unique(dicom_slice)\n",
    "            labels = labels_for_image(vertebrae)\n",
    "            train_image_labels.append(labels)\n",
    "            train_images_path = os.path.join(TRAIN_IMAGE_PATH, file_path.split(\"/\")[-1].replace('.nii', \"\"))\n",
    "            image_dir = os.listdir(train_images_path)\n",
    "            image_dir.sort(key=natural_keys)\n",
    "            image_path = os.path.join(train_images_path, image_dir[slice_number])\n",
    "            # decoded_image = decode_img(image_path)\n",
    "            train_images.append(image_path)\n",
    "\n",
    "     # categories = create_categories(train_image_labels)\n",
    "    dataset_size = len(train_images)\n",
    "    val_size = int(dataset_size * 0.2)\n",
    "    x_t = train_images[val_size:]\n",
    "    y_t = train_image_labels[val_size:]\n",
    "\n",
    "    x_v = train_images[:val_size]\n",
    "    y_v = train_image_labels[:val_size]\n",
    "\n",
    "    return x_t, y_t, x_v, y_v\n",
    "\n",
    "x_train, y_train, x_val, y_val = preprocess_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_categories(labels_for_categories):\n",
    "    vocab = [1, 2, 3, 4, 5, 6, 7]\n",
    "    index = IntegerLookup(vocabulary=vocab)\n",
    "    encoder = CategoryEncoding(num_tokens=index.vocabulary_size(), output_mode='multi_hot')\n",
    "    categories = encoder(index(labels_for_categories))\n",
    "\n",
    "    return tf.reshape(categories, [8])\n",
    "\n",
    "def decode_img(path):\n",
    "    with open(path, 'rb') as image_file:\n",
    "        ds = dcmread(image_file)\n",
    "        img = ds.pixel_array\n",
    "        img = img / 255\n",
    "        img = tf.reshape(img, [512, 512, 1])\n",
    "\n",
    "        return img\n",
    "\n",
    "def combine_image_and_labels(filename, labels):\n",
    "    labels = create_categories(labels)\n",
    "    image = decode_img(filename)\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "def create_dataset(filepaths, labels, is_training=True):\n",
    "    # test_return = combine_image_and_labels(train_images[0], train_image_labels[0])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "    dataset = dataset.map(lambda path, label: tf.py_function(func=combine_image_and_labels, inp=[path, label], Tout=(tf.float64, tf.float32)), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    dataset.map(combine_image_and_labels, num_parallel_calls=AUTOTUNE)\n",
    "    # train_dataset = tf.data.Dataset.from_tensor_slices((np.array(x_train), y_train))\n",
    "\n",
    "    if is_training:\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.shuffle(buffer_size=len(filepaths))\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(x_train, y_train)\n",
    "train_dataset = train_ds\n",
    "val_ds = create_dataset(x_val, y_val)\n",
    "val_dataset = val_ds\n",
    "\n",
    "for f, l in train_dataset.take(1):\n",
    "    print(f.shape)\n",
    "    print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
    "def upper_case_fn(t: np.ndarray):\n",
    "  return t.decode('utf-8').upper()\n",
    "# d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
    "#           inp=[x], Tout=tf.string))\n",
    "d = d.map(lambda x: upper_case_fn(x))\n",
    "list(d.as_numpy_iterator())\n",
    "\n",
    "\n",
    "\n",
    "# dataset = tf.data.Dataset.range(3)\n",
    "#\n",
    "# def g(x):\n",
    "#   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
    "# result = dataset.map(g)\n",
    "# result.element_spec\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "import keras.layers as layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def create_model():\n",
    "    seq_model = Sequential([\n",
    "        layers.Conv2D(64, 7, padding='same', activation='relu', input_shape=(512, 512, 1)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(8, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return seq_model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.summary()\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "# loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    ")\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "#     start_time = time.time()\n",
    "#\n",
    "#     for step, (x_batch_train, y_batch_train) in enumerate(train_ds):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             logits = model(x_batch_train, training=True)\n",
    "#             loss_value = loss_fn(y_batch_train, logits)\n",
    "#\n",
    "#         grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "#         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "#\n",
    "#         if step % 200 == 0:\n",
    "#             print(\n",
    "#                 \"Training loss (for one batch) at step %d: %.4f\"\n",
    "#                 % (step, float(loss_value))\n",
    "#             )\n",
    "#             print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = model(x, training=training)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "# l = loss(model, features, labels, training=False)\n",
    "# print(\"Loss test: {}\".format(l))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#  Loss function for training on breaks\n",
    "\n",
    "def get_weight(key, value):\n",
    "    is_vertebrae = re.match(r'^C[1-9]$', key)\n",
    "    if is_vertebrae and value == 0:\n",
    "        return 1\n",
    "    elif is_vertebrae and value == 1:\n",
    "        return 2\n",
    "    elif key == 'patient_overall' and value == 0:\n",
    "        return 7\n",
    "    elif key == 'patient_overall' and value == 1:\n",
    "        return 14\n",
    "\n",
    "def loss(patient_id):\n",
    "    df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    patient_row = df.loc[df['StudyInstanceUID'] == patient_id]\n",
    "    total_loss = 0\n",
    "    for i in range(1, patient_row.shape[1]):\n",
    "        key = patient_row.iloc[:, i].name\n",
    "        y_ij = patient_row.iloc[:, i].values[0]\n",
    "        w_j = get_weight(key, y_ij)\n",
    "        p_ij = random.uniform(0, 1)\n",
    "        total_loss += w_j * (y_ij * np.log(p_ij) + (1 - y_ij) * np.log(1 - p_ij))\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "loss('1.2.826.0.1.3680043.780')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.layers import CategoryEncoding, IntegerLookup\n",
    "\n",
    "# vocab = [1, 2, 3, 4, 5, 6, 7]\n",
    "# vertebrae = tf.constant([[0, 0], [1, 1], [1, 2], [5, 6], [8, 9], [2, 3]])\n",
    "# index = IntegerLookup(vocabulary=vocab)\n",
    "# encoder = CategoryEncoding(num_tokens=index.vocabulary_size(), output_mode='multi_hot')\n",
    "# categories = encoder(index(vertebrae))\n",
    "# print(categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_array = [[0], [1], [1, 2], [8, 9], [1, 2, 3]]\n",
    "# convert to list of 7 taking the first number adding it as padding to fill missing numbers\n",
    "labels_padded = []\n",
    "# for labels in label_array:\n",
    "#     labels_padded = []\n",
    "#     new_list = [labels[len(labels) - 1] if i >= len(labels) or labels[i] > 8 else labels[i] for i in range(0, 8)]\n",
    "    # for i in range(0, 8):\n",
    "    #     if i >= len(labels):\n",
    "    #         labels_padded.append(labels[len(labels) - 1])\n",
    "    #     else:\n",
    "    #         labels_padded.append(labels[i])\n",
    "\n",
    "\n",
    "# with open(os.path.join(train_images_path, image_dir[0]), 'rb') as file:\n",
    "#     ds = dcmread(file)\n",
    "#     print(ds.pixel_array.shape)\n",
    "\n",
    "\n",
    "\n",
    "# with open(image_path, 'rb') as file:\n",
    "#     ds = dcmread(file)\n",
    "#     image_tensor = tf.convert_to_tensor(ds.pixel_array)\n",
    "\n",
    "# def decode_img(img):\n",
    "#   # Convert the compressed string to a 3D uint8 tensor\n",
    "#   img = tf.io.decode_jpeg(img, channels=3)\n",
    "#   # Resize the image to the desired size\n",
    "#   return tf.image.resize(img, [180, 180])\n",
    "#\n",
    "# def process_path(file_path):\n",
    "#   # Load the raw data from the file as a string\n",
    "#   img = tf.io.read_file(file_path)\n",
    "#   img = decode_img(img)\n",
    "#   return img\n",
    "#\n",
    "# image_path = \"/home/cbarb15/PycharmProjects/RSNACervicalSpineFractureDetection/train_images/1.2.826.0.1.3680043.780/1.dcm\"\n",
    "#\n",
    "# with open(image_path, 'rb') as file:\n",
    "#     ds = dcmread(file)\n",
    "#     image_tensor = tf.convert_to_tensor(ds.pixel_array)\n",
    "#     process_path()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CURRENT_DIR_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mCURRENT_DIR_PATH\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflower_photos/daisy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m list_ds \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mlist_files(\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/*.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_image\u001B[39m(filename):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CURRENT_DIR_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "path = os.path.join(CURRENT_DIR_PATH, \"flower_photos/daisy\")\n",
    "list_ds = tf.data.Dataset.list_files(str(f'{path}/*.jpg'))\n",
    "\n",
    "def parse_image(filename):\n",
    "  parts = tf.strings.split(filename, os.sep)\n",
    "  label = parts[-2]\n",
    "\n",
    "  image = tf.io.read_file(filename)\n",
    "  image = tf.io.decode_jpeg(image)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, [128, 128])\n",
    "  return image, label\n",
    "\n",
    "# file_path = next(iter(list_ds))\n",
    "# image, label = parse_image(file_path)\n",
    "\n",
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(label.numpy().decode('utf-8'))\n",
    "  plt.axis('off')\n",
    "\n",
    "images_ds = list_ds.map(parse_image)\n",
    "for image, label in images_ds.take(2):\n",
    "    show(image, label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}